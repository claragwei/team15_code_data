# -*- coding: utf-8 -*-
"""KGCN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16GQ6mUgkIeGLLOtLJeuVuJA4KI_jKBI5
"""

import random, time, ast, joblib
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from pymongo import MongoClient
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, roc_curve, auc, precision_recall_curve
from sklearn.model_selection import train_test_split
from torch_geometric.data import HeteroData
from torch_geometric.loader import NeighborLoader
from torch_geometric.nn import HeteroConv, SAGEConv
from torch.cuda.amp import autocast, GradScaler
import matplotlib.pyplot as plt

# Config
SEED = 160
random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)

CAT_EMB_DIM = 12      # smaller to save memory
HIDDEN = 128
BATCH_SIZE = 256
NUM_NEIGHBORS = [10, 5]
MAX_EDGES = 5000
MAX_CAST_EDGES = 10000
EPOCHS = 20
LR = 5e-4
WEIGHT_DECAY = 1e-5
PATIENCE = 6
GRAD_CLIP_NORM = 2.0
MONGO_URI = "mongodb+srv://cinemaniacs:filmlytics@filmlytics.1emhcue.mongodb.net/?appName=filmlytics"

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

# 1) Load data from Mongo
client = MongoClient(MONGO_URI)
df = pd.DataFrame(list(client.cinemaniacs.movies.find({})))
print("Loaded movies:", len(df))

# Helpers
def safe_get(d, key, default=None):
    return d.get(key, default) if isinstance(d, dict) else default

def first_or_none(lst):
    if isinstance(lst, list) and len(lst) > 0:
        return lst[0]
    return None

def parse_pct_string(s):
    """Parse '66%' -> 0.66, handle None/''/non-string"""
    if isinstance(s, str):
        s = s.strip()
        if s.endswith("%"):
            try:
                return float(s[:-1]) / 100.0
            except:
                return None
    return None

def safe_literal_eval(s):
    if isinstance(s, str):
        try:
            return ast.literal_eval(s)
        except:
            return None
    return s

# 2) Extract features & parse RT percent labels
# numeric nested fields
df["budget"] = df["production"].apply(lambda x: safe_get(x, "budget", 0))
df["runtime"] = df["production"].apply(lambda x: safe_get(x, "runtime", 0))
df["vote_count"] = df["tmdb_metrics"].apply(lambda x: safe_get(x, "vote_count", 0))
df["vote_average"] = df["tmdb_metrics"].apply(lambda x: safe_get(x, "vote_average", 0))

# rotten tomatoes percentages
def extract_rt_scores(rt_obj):
    if not isinstance(rt_obj, dict):
        return (None, None)
    critic = rt_obj.get("critic_score")
    audience = rt_obj.get("audience_score")
    return (parse_pct_string(critic), parse_pct_string(audience))

rt_parsed = df["rotten_tomatoes"].apply(lambda x: extract_rt_scores(x))
df["critic_score_parsed"] = [t[0] for t in rt_parsed]
df["audience_score_parsed"] = [t[1] for t in rt_parsed]

# categorical / list features
df["genres"] = df["production"].apply(lambda x: safe_get(x, "genres", []))
df["company"] = df["production"].apply(lambda x: first_or_none(safe_get(x, "production_companies", [])))
df["director"] = df["people"].apply(lambda x: first_or_none(safe_get(x, "directors", [])))
df["cast"] = df["people"].apply(lambda x: safe_get(x, "cast", []))
df["countries"] = df["production"].apply(lambda x: safe_get(x, "production_countries", []))

# dtype safety for numeric fields
num_features = ["budget","runtime","vote_count","vote_average","critic_score_parsed","audience_score_parsed"]
for f in num_features:
    df[f] = pd.to_numeric(df[f], errors="coerce")

df["budget"] = df["budget"].fillna(0.0)
df["runtime"] = df["runtime"].fillna(0.0)
df["vote_count"] = df["vote_count"].fillna(0.0)
df["vote_average"] = df["vote_average"].fillna(0.0)

# 2b) Parse diversity and build numeric diversity features
def parse_diversity_row(d):
    out = {
        "female_cast_count": 0,
        "male_cast_count": 0,
        "female_cast_pct": 0.0,
        "gender_balance_score": 0.0,
        "director_gender": 0,
        "female_director": 0,
        "cast_unknown_cnt": 0,
        "cast_female_cnt": 0,
        "cast_male_cnt": 0,
        "cast_nonbinary_cnt": 0
    }
    if not isinstance(d, dict):
        return out

    out["female_cast_count"] = d.get("female_cast_count", 0) or 0
    out["male_cast_count"] = d.get("male_cast_count", 0) or 0

    out["female_cast_pct"] = (d.get("female_cast_percentage", 0) or 0) / 100.0
    out["gender_balance_score"] = (d.get("gender_balance_score", 0) or 0) / 100.0

    dg = d.get("director_gender", 0)
    out["director_gender"] = dg if isinstance(dg, (int,float)) else 0
    out["female_director"] = 1 if out["director_gender"] == 1 else 0

    cast_genders = d.get("cast_genders")
    cast_genders = safe_literal_eval(cast_genders)
    if isinstance(cast_genders, list):
        for g in cast_genders:
            if g == 0:
                out["cast_unknown_cnt"] += 1
            elif g == 1:
                out["cast_female_cnt"] += 1
            elif g == 2:
                out["cast_male_cnt"] += 1
            elif g == 3:
                out["cast_nonbinary_cnt"] += 1

    for k in out:
        if isinstance(out[k], (list, dict)):
            out[k] = 0
    return out

div_parsed = df["diversity"].apply(parse_diversity_row)
div_df = pd.DataFrame(list(div_parsed))
for col in div_df.columns:
    df[col] = div_df[col].fillna(0)

# 3) Build label mask & splits
labeled_mask = df["audience_score_parsed"].notna().values
labeled_idx = np.where(labeled_mask)[0]
print("Labeled movies (audience_score present):", len(labeled_idx), "out of", len(df))

if len(labeled_idx) == 0:
    raise RuntimeError("No labeled movies found. Consider predicting tmdb vote_average instead.")

train_idx, test_idx = train_test_split(labeled_idx, test_size=0.2, random_state=SEED)
train_idx, val_idx = train_test_split(train_idx, test_size=0.125, random_state=SEED)
print("Split sizes -> train:", len(train_idx), "val:", len(val_idx), "test:", len(test_idx))

# 4) Prepare movie numeric feature matrix (include diversity)
movie_feature_cols = [
    "budget","runtime","vote_count","vote_average",
    "critic_score_parsed","description_sentiment_score",
    "female_cast_count","male_cast_count","female_cast_pct","gender_balance_score",
    "director_gender","female_director",
    "cast_unknown_cnt","cast_female_cnt","cast_male_cnt","cast_nonbinary_cnt"
]

for c in movie_feature_cols:
    if c not in df.columns:
        df[c] = 0.0

df[movie_feature_cols] = df[movie_feature_cols].fillna(0.0)
scaler = StandardScaler()
X_movies = scaler.fit_transform(df[movie_feature_cols].values.astype(np.float32))
y_audience = df["audience_score_parsed"].values  # contains NaN for unlabeled

# 5) Node id maps and hetero graph construction (memory-safe)
num_movies = len(df)
movie_ids = {i: i for i in range(num_movies)}

genre_set = {g for glist in df["genres"] for g in glist}
genre_ids = {g:i for i,g in enumerate(sorted(genre_set))}
director_set = {d for d in df["director"] if pd.notna(d)}
director_ids = {d:i for i,d in enumerate(sorted(director_set))}
company_set = {c for c in df["company"] if pd.notna(c)}
company_ids = {c:i for i,c in enumerate(sorted(company_set))}
cast_set = {c for clist in df["cast"] for c in clist}
cast_ids = {c:i for i,c in enumerate(sorted(cast_set))}
country_set = {c for clist in df["countries"] for c in clist}
country_ids = {c:i for i,c in enumerate(sorted(country_set))}

print("Counts -> movies:", num_movies, "genres:", len(genre_ids), "directors:", len(director_ids),
      "companies:", len(company_ids), "cast:", len(cast_ids), "countries:", len(country_ids))

data = HeteroData()
data["movie"].x = torch.tensor(X_movies, dtype=torch.float32)
# store y (0 for unlabeled) and a boolean mask so loss can ignore unlabeled nodes
data["movie"].y = torch.tensor(np.nan_to_num(y_audience, nan=0.0), dtype=torch.float32)
data["movie"].y_mask = torch.tensor(~np.isnan(y_audience), dtype=torch.bool)   # True for labeled nodes

# placeholders for categorical nodes (embeddings will be used)
if len(genre_ids)>0: data["genre"].x = torch.zeros(len(genre_ids), CAT_EMB_DIM)
if len(director_ids)>0: data["director"].x = torch.zeros(len(director_ids), CAT_EMB_DIM)
if len(company_ids)>0: data["company"].x = torch.zeros(len(company_ids), CAT_EMB_DIM)
if len(cast_ids)>0: data["cast"].x = torch.zeros(len(cast_ids), CAT_EMB_DIM)
if len(country_ids)>0: data["country"].x = torch.zeros(len(country_ids), CAT_EMB_DIM)

def build_edges(col, node_ids, max_edges=MAX_EDGES):
    src, dst = [], []
    for i, items in enumerate(df[col]):
        if not items:
            continue
        items_list = items if isinstance(items, list) else [items]
        for it in items_list:
            if it in node_ids:
                src.append(movie_ids[i]); dst.append(node_ids[it])
    if len(src) > max_edges:
        idxs = random.sample(range(len(src)), max_edges)
        src = [src[i] for i in idxs]; dst = [dst[i] for i in idxs]
    if len(src) == 0:
        return torch.empty((2,0), dtype=torch.long)
    return torch.tensor([src,dst], dtype=torch.long)

# relations: forward + reverse (so movie gets updated)
data["movie","has_genre","genre"].edge_index = build_edges("genres", genre_ids)
data["genre","genre_of","movie"].edge_index = data["movie","has_genre","genre"].edge_index.flip(0)

data["movie","directed_by","director"].edge_index = build_edges("director", director_ids)
data["director","director_of","movie"].edge_index = data["movie","directed_by","director"].edge_index.flip(0)

data["movie","produced_by","company"].edge_index = build_edges("company", company_ids)
data["company","company_of","movie"].edge_index = data["movie","produced_by","company"].edge_index.flip(0)

data["movie","has_cast","cast"].edge_index = build_edges("cast", cast_ids, max_edges=MAX_CAST_EDGES)
data["cast","acted_in","movie"].edge_index = data["movie","has_cast","cast"].edge_index.flip(0)

data["movie","made_in","country"].edge_index = build_edges("countries", country_ids)
data["country","country_of","movie"].edge_index = data["movie","made_in","country"].edge_index.flip(0)

torch.save(data, "movie_kgcn_fullgraph_diversity_optionB.pt")
print("Saved graph → movie_kgcn_fullgraph_diversity_optionB.pt")

# 6) NeighborLoader setup (input nodes must be CPU tensors)
train_idx_tensor = torch.tensor(train_idx, dtype=torch.long)   # KEEP ON CPU!
val_idx_tensor   = torch.tensor(val_idx, dtype=torch.long)
test_idx_tensor  = torch.tensor(test_idx, dtype=torch.long)

train_loader = NeighborLoader(
    data,
    input_nodes=("movie", train_idx_tensor),
    num_neighbors=NUM_NEIGHBORS,
    batch_size=BATCH_SIZE,
    shuffle=True,
)

val_loader = NeighborLoader(
    data,
    input_nodes=("movie", val_idx_tensor),
    num_neighbors=NUM_NEIGHBORS,
    batch_size=BATCH_SIZE,
    shuffle=False,
)

# 7) HeteroKGCN model (batch-safe + device-safe)
movie_feat_dim = data["movie"].x.shape[1]
print("Movie numeric feature dim:", movie_feat_dim)

class HeteroKGCN_v2(nn.Module):
    def __init__(self, movie_feat_dim, cat_emb_dim=CAT_EMB_DIM, hidden=HIDDEN, dropout=0.4):
        super().__init__()
        # embeddings (movie embedding gives node-specific learned vector)
        self.movie_emb = nn.Embedding(num_movies, cat_emb_dim)
        self.genre_emb = nn.Embedding(len(genre_ids), cat_emb_dim) if len(genre_ids)>0 else None
        self.director_emb = nn.Embedding(len(director_ids), cat_emb_dim) if len(director_ids)>0 else None
        self.company_emb = nn.Embedding(len(company_ids), cat_emb_dim) if len(company_ids)>0 else None
        # make cast embeddings smaller to save memory
        self.cast_emb = nn.Embedding(len(cast_ids), max(8, cat_emb_dim//2)) if len(cast_ids)>0 else None
        self.country_emb = nn.Embedding(len(country_ids), cat_emb_dim) if len(country_ids)>0 else None

        conv1 = {}
        conv2 = {}
        def add(src, rel, dst, src_dim, dst_dim):
            conv1[(src,rel,dst)] = SAGEConv((src_dim, dst_dim), hidden)
            conv2[(src,rel,dst)] = SAGEConv((hidden, hidden), hidden)

        add('movie','has_genre','genre', movie_feat_dim+cat_emb_dim, cat_emb_dim)
        add('genre','genre_of','movie', cat_emb_dim, movie_feat_dim+cat_emb_dim)
        if self.director_emb is not None:
            add('movie','directed_by','director', movie_feat_dim+cat_emb_dim, cat_emb_dim)
            add('director','director_of','movie', cat_emb_dim, movie_feat_dim+cat_emb_dim)
        if self.company_emb is not None:
            add('movie','produced_by','company', movie_feat_dim+cat_emb_dim, cat_emb_dim)
            add('company','company_of','movie', cat_emb_dim, movie_feat_dim+cat_emb_dim)
        if self.cast_emb is not None:
            add('movie','has_cast','cast', movie_feat_dim+cat_emb_dim, self.cast_emb.embedding_dim)
            add('cast','acted_in','movie', self.cast_emb.embedding_dim, movie_feat_dim+cat_emb_dim)
        if self.country_emb is not None:
            add('movie','made_in','country', movie_feat_dim+cat_emb_dim, cat_emb_dim)
            add('country','country_of','movie', cat_emb_dim, movie_feat_dim+cat_emb_dim)

        self.conv1 = HeteroConv(conv1, aggr='sum')
        self.conv2 = HeteroConv(conv2, aggr='sum')

        self.dropout = nn.Dropout(0.4)
        self.ln = nn.LayerNorm(hidden)
        self.lin = nn.Linear(hidden, 1)

    def forward(self, x_dict, edge_index_dict, batch=None):
        # device-safe movement
        dev = next(self.parameters()).device
        # move only available tensors to device
        x = {k: v.to(dev) for k,v in x_dict.items()}
        ei = {k: v.to(dev) for k,v in edge_index_dict.items()}

        # movie embedding per-batch or full
        if batch is not None:
            movie_idx = batch["movie"].n_id.to(self.movie_emb.weight.device)
            movie_emb_batch = self.movie_emb(movie_idx)
            x["movie"] = torch.cat([x["movie"].to(movie_emb_batch.device), movie_emb_batch], dim=1)
        else:
            x["movie"] = torch.cat([x["movie"], self.movie_emb.weight.to(x["movie"].device)], dim=1)

        dev2 = x["movie"].device
        if self.genre_emb is not None: x["genre"] = self.genre_emb.weight.to(dev2)
        if self.director_emb is not None: x["director"] = self.director_emb.weight.to(dev2)
        if self.company_emb is not None: x["company"] = self.company_emb.weight.to(dev2)
        if self.cast_emb is not None: x["cast"] = self.cast_emb.weight.to(dev2)
        if self.country_emb is not None: x["country"] = self.country_emb.weight.to(dev2)

        x = self.conv1(x, ei)
        x = {k: torch.relu(v) for k,v in x.items()}
        x = self.conv2(x, ei)

        out = self.lin(self.dropout(self.ln(x["movie"]))).squeeze()
        return out

# instantiate model + optimizer + scheduler + amp scaler
model = HeteroKGCN_v2(movie_feat_dim=movie_feat_dim, cat_emb_dim=CAT_EMB_DIM, hidden=HIDDEN).to(device)
optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)
scaler_amp = GradScaler()
loss_fn = nn.MSELoss()

# 8) Training loop (masked loss, AMP, gradclip, early stopping)

best_val = float("inf")
best_state = None
no_improve = 0

print("Starting training...")
t0 = time.time()
for epoch in range(1, EPOCHS+1):
    model.train()
    total_loss = 0.0
    steps = 0

    for batch in train_loader:
        optimizer.zero_grad()
        # forward + masked loss
        with autocast():
            out = model(batch.x_dict, batch.edge_index_dict, batch=batch)   # shape: [num_movie_nodes_in_batch]
            y_batch = batch["movie"].y.to(device)
            mask_batch = batch["movie"].y_mask.to(device)
            # if no labeled nodes in batch, skip
            if mask_batch.sum().item() == 0:
                continue
            pred = out[mask_batch]
            true = y_batch[mask_batch]
            loss = loss_fn(pred, true)

        # backward with AMP
        scaler_amp.scale(loss).backward()
        scaler_amp.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP_NORM)
        scaler_amp.step(optimizer)
        scaler_amp.update()

        total_loss += loss.item()
        steps += 1

    train_loss = total_loss/steps if steps>0 else float("nan")

    # validation
    model.eval()
    val_losses = []
    with torch.no_grad():
        for vbatch in val_loader:
            with autocast():
                vout = model(vbatch.x_dict, vbatch.edge_index_dict, batch=vbatch)
                y_v = vbatch["movie"].y.to(device)
                mask_v = vbatch["movie"].y_mask.to(device)
                if mask_v.sum().item() == 0:
                    continue
                vpred = vout[mask_v]
                vtrue = y_v[mask_v]
                vloss = loss_fn(vpred, vtrue)
            val_losses.append(vloss.item())
    mean_val = np.mean(val_losses) if len(val_losses)>0 else float("inf")
    scheduler.step(mean_val)

    print(f"Epoch {epoch}/{EPOCHS} | Train Loss: {train_loss:.6f} | Val Loss: {mean_val:.6f}")

    # checkpoint & early stopping (on validation loss)
    if mean_val < best_val - 1e-7:
        best_val = mean_val
        best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}
        no_improve = 0
        torch.save({"state": best_state}, "best_hetero_kgcn_ckpt.pth")
    else:
        no_improve += 1
        if no_improve >= PATIENCE:
            print("Early stopping triggered.")
            break

print("Training done in {:.1f}s".format(time.time()-t0))

# load best weights
if best_state is not None:
    model.load_state_dict({k:v.to(device) for k,v in best_state.items()})

# 9) Full-graph inference & evaluation on test labeled indices
model.eval()
with torch.no_grad():
    preds_full = model(data.x_dict, data.edge_index_dict, batch=None).cpu().numpy()
    # clip predictions to [0,1]
    preds_full = np.clip(preds_full, 0.0, 1.0)
    trues_full = data["movie"].y.cpu().numpy()

# Evaluate on test split (held-out labeled)
test_idx_np = np.array(test_idx)
y_true_test = trues_full[test_idx_np]
y_pred_test = preds_full[test_idx_np]

mae = mean_absolute_error(y_true_test, y_pred_test)
mse = mean_squared_error(y_true_test, y_pred_test)
rmse = np.sqrt(mse)
r2 = r2_score(y_true_test, y_pred_test)
corr = np.corrcoef(y_true_test, y_pred_test)[0,1] if (np.std(y_true_test)>0 and np.std(y_pred_test)>0) else float('nan')

print("\n=== Final Evaluation on Held-out RT audience_score Movies ===")
print(f"Test examples: {len(test_idx_np)}")
print(f"MAE:  {mae:.4f}")
print(f"RMSE: {rmse:.4f}")
print(f"R²:   {r2:.4f}")
print(f"Pearson: {corr:.4f}")

# Save model & scaler
torch.save(model.state_dict(), "hetero_kgcn_v2_optionB.pth")
joblib.dump(scaler, "movie_feature_scaler_diversity.pkl")
pd.DataFrame({"pred_audience_score": preds_full, "true_audience_score": trues_full}).to_csv("kgcn_preds_all_movies.csv", index=True)
print("Saved model, scaler, and predictions CSV")

# Visualizations
mask_labeled = ~np.isnan(trues_full)
trues_labeled = trues_full[mask_labeled]
preds_labeled = preds_full[mask_labeled]
print("Labeled count for viz:", len(trues_labeled))

# Scatter: truth vs pred
plt.figure(figsize=(6,6))
plt.scatter(trues_labeled, preds_labeled, alpha=0.35)
plt.xlabel("True Audience Score"); plt.ylabel("Predicted Audience Score")
plt.title("Predicted vs True Audience Score (Labeled Movies)")
plt.plot([0,1],[0,1], '--', color='red')
plt.tight_layout(); plt.show()

# Residual histogram
errors = preds_labeled - trues_labeled
plt.figure(figsize=(7,5)); plt.hist(errors, bins=40); plt.xlabel("Prediction Error (pred - true)"); plt.title("Residual Distribution"); plt.tight_layout(); plt.show()

# Density hexbin
plt.figure(figsize=(7,6))
plt.hexbin(trues_labeled, preds_labeled, gridsize=40)
plt.xlabel("True Audience Score"); plt.ylabel("Predicted Audience Score")
plt.title("Density: True vs Predicted (Labeled Movies)"); plt.colorbar(label="Count"); plt.tight_layout(); plt.show()

# ROC + PR (binary threshold 0.6)
y_true_bin = (trues_labeled >= 0.6).astype(int)
y_score = preds_labeled
if len(np.unique(y_true_bin)) > 1:
    fpr, tpr, _ = roc_curve(y_true_bin, y_score)
    roc_auc = auc(fpr, tpr)
    prec, rec, _ = precision_recall_curve(y_true_bin, y_score)
    pr_auc = auc(rec, prec)

    plt.figure(figsize=(6,6))
    plt.plot(fpr, tpr, label=f'ROC AUC = {roc_auc:.3f}')
    plt.plot([0,1],[0,1],'--', color='gray')
    plt.xlabel("FPR"); plt.ylabel("TPR"); plt.title("ROC Curve (audience >= 0.6)")
    plt.legend(); plt.tight_layout(); plt.show()

    plt.figure(figsize=(6,6))
    plt.plot(rec, prec, label=f'PR AUC = {pr_auc:.3f}')
    plt.xlabel("Recall"); plt.ylabel("Precision"); plt.title("Precision-Recall Curve (audience >= 0.6)")
    plt.legend(); plt.tight_layout(); plt.show()
else:
    print("Not enough positives/negatives in labeled set to compute ROC/PR.")